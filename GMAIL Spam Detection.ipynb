{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8485c988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994c04d0",
   "metadata": {},
   "source": [
    "# Loading DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d352680a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6   ham  Even my brother is not like to speak with me. ...\n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8  spam  WINNER!! As a valued network customer you have...\n",
       "9  spam  Had your mobile 11 months or more? U R entitle..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = pd.read_csv(\"spam.csv\")\n",
    "dt.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d3e6240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text  spam\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     0\n",
       "1   ham                      Ok lar... Joking wif u oni...     0\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     1\n",
       "3   ham  U dun say so early hor... U c already then say...     0\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...     0\n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...     1\n",
       "6   ham  Even my brother is not like to speak with me. ...     0\n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...     0\n",
       "8  spam  WINNER!! As a valued network customer you have...     1\n",
       "9  spam  Had your mobile 11 months or more? U R entitle...     1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['spam'] = dt['type'].map({'spam' : 1, 'ham' : 0}).astype(int)\n",
    "dt.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9dd74a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMS IN THE GIVEN DATA:\n",
      "type\n",
      "text\n",
      "spam\n"
     ]
    }
   ],
   "source": [
    "print(\"COLUMS IN THE GIVEN DATA:\")\n",
    "for col in dt.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c673523f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO OF ROWS IN REVIEW COLUMN: 116\n",
      "NO OF ROWS IN liked COLUMN: 116\n"
     ]
    }
   ],
   "source": [
    "t = len(dt['type'])\n",
    "print(\"NO OF ROWS IN REVIEW COLUMN:\",t)\n",
    "t = len(dt['text'])\n",
    "print(\"NO OF ROWS IN liked COLUMN:\",t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9cb50d",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb2fb208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ok lar... Joking wif u oni...'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5675f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3577b5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['text'] = dt['text'].apply(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe47ea27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ok', 'lar...', 'Joking', 'wif', 'u', 'oni...']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['text'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951a6a69",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95f2acc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ok', 'lar...', 'Joking', 'wif', 'u', 'oni...']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45c0ef25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "porter = SnowballStemmer(\"english\", ignore_stopwords=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6b49b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_it(text):\n",
    "    return [porter.stem(word) for word in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "781d137c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['text'] = dt['text'].apply(stem_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0788d84a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ok', 'lar...', 'joke', 'wif', 'u', 'oni...']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['text'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd7d759",
   "metadata": {},
   "source": [
    "# Lemmitization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5972fba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'know!',\n",
       " 'grumpi',\n",
       " 'old',\n",
       " 'people.',\n",
       " 'my',\n",
       " 'mom',\n",
       " 'was',\n",
       " 'like',\n",
       " 'you',\n",
       " 'good',\n",
       " 'not',\n",
       " 'be',\n",
       " 'lying.',\n",
       " 'then',\n",
       " 'again',\n",
       " 'i',\n",
       " 'am',\n",
       " 'alway',\n",
       " 'the',\n",
       " 'one',\n",
       " 'to',\n",
       " 'play',\n",
       " 'jokes...']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['text'][109]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e0160c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ef9c31be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmit_it(text):\n",
    "    return [lemmatizer.lemmatize(word, pos = 'a') for word in text]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a2ff1739",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['text'] = dt['text'].apply(lemmit_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a311f8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'know!',\n",
       " 'grumpi',\n",
       " 'old',\n",
       " 'people.',\n",
       " 'my',\n",
       " 'mom',\n",
       " 'was',\n",
       " 'like',\n",
       " 'you',\n",
       " 'good',\n",
       " 'not',\n",
       " 'be',\n",
       " 'lying.',\n",
       " 'then',\n",
       " 'again',\n",
       " 'i',\n",
       " 'am',\n",
       " 'alway',\n",
       " 'the',\n",
       " 'one',\n",
       " 'to',\n",
       " 'play',\n",
       " 'jokes...']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['text'][109]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee58d6f",
   "metadata": {},
   "source": [
    "# Stopword Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "27003a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'know!',\n",
       " 'grumpi',\n",
       " 'old',\n",
       " 'people.',\n",
       " 'my',\n",
       " 'mom',\n",
       " 'was',\n",
       " 'like',\n",
       " 'you',\n",
       " 'good',\n",
       " 'not',\n",
       " 'be',\n",
       " 'lying.',\n",
       " 'then',\n",
       " 'again',\n",
       " 'i',\n",
       " 'am',\n",
       " 'alway',\n",
       " 'the',\n",
       " 'one',\n",
       " 'to',\n",
       " 'play',\n",
       " 'jokes...']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['text'][109]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "780bcf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3bb6c637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_it(text):\n",
    "    review = [word for word in text if not word in stop_words]\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ba09fb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['text'] = dt['text'].apply(stop_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4016b83e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['know!',\n",
       " 'grumpi',\n",
       " 'old',\n",
       " 'people.',\n",
       " 'mom',\n",
       " 'like',\n",
       " 'good',\n",
       " 'lying.',\n",
       " 'alway',\n",
       " 'one',\n",
       " 'play',\n",
       " 'jokes...']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['text'][109]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "68371e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[go, jurong, point,, crazy.., avail, onli, bug...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[ok, lar..., joke, wif, u, oni...]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[u, dun, say, earli, hor..., u, c, alreadi, sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[nah, think, goe, usf,, live, around, though]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>[freemsg, hey, darl, 3, week, word, back!, i'd...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>[even, brother, like, speak, me., treat, like,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>[per, request, mell, mell, (oru, minnaminungin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>[winner!!, valu, network, custom, select, rece...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>[mobil, 11, month, more?, u, r, entitl, updat,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text  spam\n",
       "0   ham  [go, jurong, point,, crazy.., avail, onli, bug...     0\n",
       "1   ham                 [ok, lar..., joke, wif, u, oni...]     0\n",
       "2  spam  [free, entri, 2, wkli, comp, win, fa, cup, fin...     1\n",
       "3   ham  [u, dun, say, earli, hor..., u, c, alreadi, sa...     0\n",
       "4   ham      [nah, think, goe, usf,, live, around, though]     0\n",
       "5  spam  [freemsg, hey, darl, 3, week, word, back!, i'd...     1\n",
       "6   ham  [even, brother, like, speak, me., treat, like,...     0\n",
       "7   ham  [per, request, mell, mell, (oru, minnaminungin...     0\n",
       "8  spam  [winner!!, valu, network, custom, select, rece...     1\n",
       "9  spam  [mobil, 11, month, more?, u, r, entitl, updat,...     1"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "62608a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['text'] = dt['text'].apply(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f10444a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go jurong point, crazy.. avail onli bugi n gre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar... joke wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entri 2 wkli comp win fa cup final tkts 2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say earli hor... u c alreadi say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah think goe usf, live around though</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>freemsg hey darl 3 week word back! i'd like fu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>even brother like speak me. treat like aid pat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>per request mell mell (oru minnaminungint nuru...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>winner!! valu network custom select receivea £...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>mobil 11 month more? u r entitl updat late col...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text  spam\n",
       "0   ham  go jurong point, crazy.. avail onli bugi n gre...     0\n",
       "1   ham                        ok lar... joke wif u oni...     0\n",
       "2  spam  free entri 2 wkli comp win fa cup final tkts 2...     1\n",
       "3   ham          u dun say earli hor... u c alreadi say...     0\n",
       "4   ham              nah think goe usf, live around though     0\n",
       "5  spam  freemsg hey darl 3 week word back! i'd like fu...     1\n",
       "6   ham  even brother like speak me. treat like aid pat...     0\n",
       "7   ham  per request mell mell (oru minnaminungint nuru...     0\n",
       "8  spam  winner!! valu network custom select receivea £...     1\n",
       "9  spam  mobil 11 month more? u r entitl updat late col...     1"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175c7e9d",
   "metadata": {},
   "source": [
    "# Transform Text Data into TDF/TF-IDF Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "18f2fbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "y = dt.spam.values\n",
    "x = tfidf.fit_transform(dt['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "68dfbcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_text,y_train,y_text = train_test_split(x,y,random_state=1,test_size=0.2,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7ae9db",
   "metadata": {},
   "source": [
    "# Classification using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1427e221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 87.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(x_train,y_train)\n",
    "y_pred = clf.predict(x_text)\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc_log = accuracy_score(y_pred, y_text) * 100\n",
    "print(\"accuracy:\",acc_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd1db3b",
   "metadata": {},
   "source": [
    "# Classification using Linear SVC Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8c570fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  87.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "linear_svc = LinearSVC(random_state=0)\n",
    "linear_svc.fit(x_train,y_train)\n",
    "y_pred = linear_svc.predict(x_text)\n",
    "acc_linear_svc = accuracy_score(y_pred, y_text) * 100\n",
    "print(\"accuracy: \",acc_linear_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e019cd6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
